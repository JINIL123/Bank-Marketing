---
title: "Bank Marketing Analysis"
author: "Anupam Tiwari, Jinil Amin, Prachi Hota"
date: "December 1, 2017"
output:
  word_document: default
  pdf_document: default
  html_notebook: default
---
```{r echo=FALSE, include=FALSE}
library(caret)
library(MASS)
library(ROCR)
library(readr)
library(faraway)
library(pscl)
library(e1071)
```


####<u>1. Project Summary</u>

**1.1 Introduction**

Retail Banking is a financial service provided by banks to various clients and customers. This service aims at providing savings & transaction accounts, mortgages, personal loans, and credit/debit cards to a variety of customer segment based on their financial needs. It is a very competitive business as more and more banks are starting to get involved in this industry.

One of the significant challenges the business faces is figuring out how to identify customers who are the potential customer likely to do business with them and targeting those with impact will play a vital role to win the competitive edge.

In this study, we have implemented machine learning algorithms on a bank marketing dataset. The goal is to understand the essential features affecting short-term deposit account for sign-ups and to develop a plan to help banks focus on those most promising leads to attract more customer.

**1.2 Dataset description**

The data set used here is from UCI machine learning repository. It is derived from the direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or would not be('no') subscribed.

The following categories of information are included in the data set:

Consumer data: Age, sex, job and marital status, education, loan status, and so on.
Campaign activities: When and how to contact, times to contact, outcome of previous campaigns.
Social and economic environment data: Euribor 3 month rate, employment variation rate, consumer price index, and
consumer confidence index.
Outcome:  A 'yes' for the bank if there is a term deposit subscribed, a 'no' for the other outcome.

####<u>2. Problem Statement</u>

The Portuguese bank was seeing decline in revenue and after research and investigation, it was found out that the primary cause was that their clients were not depositing as frequently as before.
The main advantage of providing term deposit service to its client is that the bank can hold the funds for a specific period Which enables banks to invest in higher financial products, to gain more profit. Also to that, banks also carry a great chance to cross-sell it other commercial product to its old customers to capture higher market value & get more ROI. Due to which, the Portuguese bank would like to identify those former clients as well as new clients who have a higher chance for a subscription to a term deposit and focus marketing effort on such clients.

####<u>3. Methodolology and Terminology</u>

**3.1 Logistic Regression**

Logistic Regression is a probabilistic classification model which is used to predict a binary response from a mix of the qualitative and quantitative predictors. The main advantage of using logistic regression in our analysis is it doesn't suffer from severe class imbalance problems.

Logistic Regression models the log odds of the event as a linear function:

This nonlinear function is a sigmoidal function of the model terms and constraints the probability estimates to between 0 and 1.

**3.2  Akaike information criterion (AIC)**

AIC is used for model selection. AIC helps to know the best model out of all other models used However if all models are imperfect, AIC will not let about that instead it gives us the best among all those poor models.

The preferred model is the one which has the minimum AIC value.

**3.3 ROC Curve and Area Under Cuvrve (AUC)**

Receiver Operating Characteristic (ROC) curve is the most commonly used to show the performance of a binary classifier. It is generated by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.

Area Under Curve (AUC) is used in classification analysis to determine which of the used models predicts the classes best. The values vary between 0 to 1. Higher values indicate that model is good at prediction.

####<u>4. Bank Marketing Analysis</u>

**4.1 Data Preprocessing & Exploratory Data Analysis**

To start our analysis, we will first import the datset into R. We will also see the data summary and structure too understand our dataset.

```{r import dataset}
bank <- read.csv("bank.csv", header = TRUE)
head(bank)
summary(bank)
```

Our data is mix of categorical and numerical variables. Our response variable is binary meaning that it has two outcomes "yes" or "no".

Now we want to check class type of each variable so accordingly, we can decide which are the variables need to be transformed.

```{r Check Class & Factor variables}
data.frame(class = sapply(bank, class), isFactor = sapply(bank, function(x) is.factor(x)))
```

As we see, we have many categorical variables, now we are checking count of unique values to know how many levels each categorical variable has.
```{r Check unique values}
data.frame(uniqueCount = sapply(bank, function(x) length(unique(x))))
```

We are also checking how R is dummyfying categorical variables and to check this we are just considering variable `job` as an example.
```{r dummified details}
contrasts(bank$job)
```

As most of time, dataset is not complete and we get many missing values whether these are missing at random or not at random so we will check if is there any value missing in our dataset, if yes, then we will analyse the situation and deside if we need to impute the missing values or we can omit them.

```{r Check Missing Values}
data.frame(missingValues = sapply(bank,function(x){sum(is.na(x))}))
```

As shown above, we do not see any missing value in our dataset hence no need to work on imputation. Now, we can move further to do other data preprocessing tasks.

```{r pre-processing}
bank$deposit <- factor(bank$deposit,levels=c("no","yes"),labels=c(0,1))
# Replacing -1 with 0 and 0 means client was not previously contacted
bank$pdays <- ifelse(bank$pdays==-1,0,bank$pdays)
```

As per our preliminary study, we will drop below variable from the dataset as these do not have any direct impact on our analysis:

`contact`, `day`
```{r Feature reduction}
bank$contact <- NULL
bank$day <- NULL
```

```{r Visualization1}
# Boxplots to check Outliers
oldpar <- par(mfrow=c(1,2))
par(mfrow=c(1,2))
plot(density(bank$age),main = "age",xlab =paste("skweness =", skewness(bank$age)))

boxplot(bank$age, ylab = "Age", main = "Box Plot")

plot(density(bank$balance),main = "balance",xlab =paste("skweness =", skewness(bank$balance)))

boxplot(bank$balance,ylab="balance")

plot(density(bank$duration),main = "duration",xlab =paste("skweness =", skewness(bank$duration)))

boxplot(bank$duration,ylab="duration")

plot(density(bank$campaign),main = "campaign",xlab =paste("skweness =", skewness(bank$campaign)))

boxplot(bank$campaign,ylab="campaign")

plot(density(bank$pdays),main = "pdays",xlab =paste("skweness =", skewness(bank$pdays)))

boxplot(bank$pdays,ylab="pdays")

plot(density(bank$previous),main = "previous",xlab =paste("skweness =", skewness(bank$previous)))

boxplot(bank$previous,ylab="previous")
par(mfrow=oldpar)
```

```{r Visualization2}
# To check the age of people who are depositing
plot1 <- qplot(deposit, age, geom = "boxplot", data=bank)
plot1
```

```{r Deposits by month}
# Pie Chart with Percentages
data <- aggregate( deposit ~ month, bank, length)
labels = levels(data$month)
pct <- round(data$deposit/sum(data$deposit)*100)
lbls <- paste(labels, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(data$deposit,labels = lbls, col=rainbow(length(lbls)),
  	main="Pie Chart of Deposits by Month")
```
```{r Age categories}
data1 <- bank[c(1,15)]
data1$ageCategory <- cut(data1$age, breaks = seq(10, 100, by = 10))
data2 <- aggregate( deposit ~ ageCategory, data1, length)
my_vector= data2$deposit
names(my_vector)=data2$ageCategory
barplot(my_vector, col=c(1:length(data2$ageCategory)), main = "Deposit by Age groups", xlab = "Age Groups", ylab = "No. of Deposits")
```
```{r Where deposit is Yes}
data1 <- bank[c(1,15)]
data1$ageCategory <- cut(data1$age, breaks = seq(10, 100, by = 10))
data2 <- aggregate( data1$deposit[data1$deposit==1] ~ data1$ageCategory[data1$deposit==1], data1, length)
my_vector= data2[,2]
names(my_vector)=data2[,1]
barplot(my_vector, col=c(1:length(data2[,1])), main = "Deposited by Age groups", xlab = "Age Groups", ylab = "No. of Deposits")
```

```{r Where deposit is No}
data1 <- bank[c(1,15)]
data1$ageCategory <- cut(data1$age, breaks = seq(10, 100, by = 10))
data2 <- aggregate( data1$deposit[data1$deposit==0] ~ data1$ageCategory[data1$deposit==0], data1, length)
my_vector= data2[,2]
names(my_vector)=data2[,1]
barplot(my_vector, col=c(1:length(data2[,1])), main = "Not Deposited by Age groups", xlab = "Age Groups", ylab = "No. of Deposits")
```


```

**4.2 Predictive Analysis & Model Building**

In order to meet the goal set up above, we need to develop a classification model with a balanced ability of giving correct prediction on both consumer sign-ups and no sign-ups. This model is considered as suitable since it can help marketing personnel to focus on those promising leads and reduce or eliminate effort on those who are unlikely to conduct business with them.

```{r Train test data}
set.seed(123)
train <- sample(1:nrow(bank), round(nrow(bank)*.8), replace = FALSE)
trainD <- bank[train,]
testD <- bank[-train,]
```

```{r model 1}
model1 <- glm(deposit~., data = trainD, family=binomial(link='logit'))
summary(model1)
```


```{r Prediction & Accuracy of model1}
pred <- predict(model1, testD, type='response')
pred <- ifelse(pred > 0.5,1,0)
confusionMatrix(pred, testD$deposit)
```

```{r Cooks Distance for detecting influential outliers}
cook <- cooks.distance(model1)
Rlabels <- row.names(bank)
halfnorm(cook, 3, labs = Rlabels, ylab = "Cook's distance")
```

```{r model 2}
model2 <- glm(deposit~., data = trainD, subset = (cook < max(cook)),family=binomial(link='logit'))
summary(model2)
```

```{r Prediction & Accuracy of model2}
pred <- predict(model2, testD, type='response')
pred <- ifelse(pred > 0.5,1,0)
confusionMatrix(pred, testD$deposit)
```

```{r Stepwise AIC}
step <- stepAIC(model2)
step$anova
```

```{r model3}
model3 <- glm(deposit ~ job + marital + education + balance + housing + loan + month + duration + campaign + poutcome, data = trainD, family=binomial(link='logit'))
summary(model3)
```

```{r Prediction & Accuracy of model3}
pred3 <- predict(model3, testD, type='response')
pred3 <- ifelse(pred3 > 0.5,1,0)
confusionMatrix(pred3, testD$deposit)
```

```{r cross-validation}
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
model4 <- train(deposit ~job + marital + education + balance + housing + loan + month + duration + campaign + poutcome,  data=trainD, method="glm", family="binomial",trControl = ctrl, tuneLength = 5)

pred4 = predict(model4, newdata=testD)
confusionMatrix(data=pred4, testD$deposit)
```

**4.3 Model Selection & Outcome**

```{r ROC measurement}
pr <- prediction(pred3,testD$deposit)
prf <- performance(pr, measure = "tpr",x.measure = "fpr")
plot(prf)
```

```{r Area Under Curve}
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(auc)
```

####<u>5. Conclusion</u>

In this study, we have applied machine learning techniques to retail bank marketing data and explored how the techniques can be used to help  the bank to conduct its marketing campaign:

####<u>6. References</u>
